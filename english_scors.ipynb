{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07691643",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px 30px 30px; \n",
    "            color:#004346;\n",
    "            font-size:40px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "<p style=\"font-weight: bold; text-align: center;\">Определение уровня сложности фильмов</p>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb2e47d",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 40px 30px; \n",
    "            color:#004346;\n",
    "            font-size:110%;\n",
    "            display:fill;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:450;\"> \n",
    "    \n",
    "__Постановка проблемы:__ Просмотр фильмов на оригинальном языке - это популярный и действенный метод прокачаться при изучении иностранных языков. Важно выбрать фильм, который подходит студенту по уровню сложности, т.е. студент понимал 50-70 % диалогов. Чтобы выполнить это условие, преподаватель должен посмотреть фильм и решить, какому уровню он соответствует. Однако это требует больших временных затрат.\n",
    "    \n",
    "__Цель:__ Разработать ML решение для автоматического определения уровня сложности англоязычных фильмов, разработать для неё веб-интерфейс и создать микросервис. \n",
    "    \n",
    "__Описание данных:__\n",
    "\n",
    "- субтитры фильмов, сохраненные в директориях, названия которых, соответствуют уровню сложности по шкале CEFR([Common European Framework of Reference]('https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%89%D0%B5%D0%B5%D0%B2%D1%80%D0%BE%D0%BF%D0%B5%D0%B9%D1%81%D0%BA%D0%B8%D0%B5_%D0%BA%D0%BE%D0%BC%D0%BF%D0%B5%D1%82%D0%B5%D0%BD%D1%86%D0%B8%D0%B8_%D0%B2%D0%BB%D0%B0%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%B8%D0%BD%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%BD%D1%8B%D0%BC_%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%BC' 'wikipedia'))\n",
    "    \n",
    "- субтитры фильмов и [фaйл xlsx](https://i.postimg.cc/8zXN4BJ6/2023-06-08-11-58-46.png), содержаший название фильмов и уровню сложности по шкале CEFR\n",
    "    \n",
    "- список слов, по уровлю сложности Oxford level.\n",
    "</div>        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf617c",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Используемые библиотеки\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338ab3d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pysrt\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import joblib\n",
    "import random\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# константы\n",
    "RANDOM_SEED = 42\n",
    "EARLY_STOPPING_ROUND = 100\n",
    "\n",
    "HTML = r'<.*?>'\n",
    "TAG = r'{.*?}'\n",
    "COMMENTS = r'[\\(\\[][A-Z ]+[\\)\\]]'\n",
    "LETTERS = r'[^a-zA-Z\\'.,!? ]'\n",
    "SPACES = r'([ ])\\1+'\n",
    "DOTS = r'[\\.]+'\n",
    "PUNCTUATION = re.compile('[^а-яa-z\\s]')\n",
    "\n",
    "# настройки блокнота\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_colwidth = None\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48897f1b",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Загрузка и первичная обработка данных\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cca8838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Данные загруженны коректно'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # путь к папке с файлами субтитров\n",
    "    subtitles_folder = Path('data/subtitles/subtitles_cerf/')\n",
    "    subtitles_folder2 = 'data/subtitles/subtitles_no_labels'\n",
    "    excel_file = 'data/subtitles/movies_labels.xlsx'\n",
    "\n",
    "    # загрузка данных для рассчета статистической информации:\n",
    "    a1_list = next(csv.reader(open('data/a1.csv', 'r')))\n",
    "    a2_list = next(csv.reader(open('data/a2.csv', 'r')))\n",
    "    b1_list = next(csv.reader(open('data/b1.csv', 'r')))\n",
    "    b2_list = next(csv.reader(open('data/b2.csv', 'r')))\n",
    "    c1_list = next(csv.reader(open('data/c1.csv', 'r')))\n",
    "    display('Данные загруженны коректно')\n",
    "except:\n",
    "    display('Данные не доступны')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035c05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для первичной обработки текста\n",
    "def clean_subs(txt):\n",
    "    txt = re.sub(HTML, ' ', txt) #html тэги меняем на пробел\n",
    "    txt = re.sub(TAG, ' ', txt) #тэги меняем на пробел\n",
    "    txt = re.sub(COMMENTS, ' ', txt) #комменты меняем на пробел\n",
    "    txt = re.sub(LETTERS, ' ', txt) #все что не буквы меняем на пробел\n",
    "    txt = re.sub(SPACES, r'\\1', txt) #повторяющиеся пробелы меняем на один пробел\n",
    "    txt = re.sub(DOTS, r'.', txt) #многоточие меняем на точку\n",
    "    txt = txt.encode('ascii', 'ignore').decode() #удаляем все что не ascii символы\n",
    "    txt = \".\".join(txt.lower().split('.')[1:-1]) #удаляем первый и последний субтитр (обычно это реклама)\n",
    "    txt = txt.replace('. .', '. ')\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e616b2",
   "metadata": {},
   "source": [
    "__Получение первой части размеченных данных__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83f42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение списока файлов субтитров в папке\n",
    "subtitles_files = subtitles_folder.rglob('*.srt')\n",
    "# cоздание пустого датафрейма для хранения данных\n",
    "df = pd.DataFrame(columns=['movie', 'subtitles', 'label'])\n",
    "# загрузка и первичня обработка субтитров\n",
    "data = []\n",
    "for file_path in subtitles_files:\n",
    "    subs = pysrt.open(str(file_path), encoding='latin-1')\n",
    "    if len(subs) == 0:\n",
    "        subs = pysrt.open(str(file_path), encoding='utf-16') #учитываем альтернативную кодировку\n",
    "    txt = ' '.join([sub.text for sub in subs])\n",
    "    subtitle_text = clean_subs(txt)\n",
    "    data.append({'movie': file_path.name[:-4], 'subtitles': subtitle_text, 'label': file_path.parent.name})\n",
    "    \n",
    "# объединяем все записи в датасете с помощью функции concat\n",
    "df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467220c",
   "metadata": {},
   "source": [
    "__Получение второй части размеченных данных__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528a3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка датафрейма из файла excel\n",
    "df2 = pd.read_excel(excel_file)\n",
    "# удаление столбца, не использующего в дальнейшем анализе: `id`\n",
    "df2 = df2.drop('id', axis=1)\n",
    "# переименование признаков для последующей конкатинации датасетов\n",
    "df2.rename(columns = {\n",
    "    'Movie':'movie',\n",
    "    'Level':'label'\n",
    "    }, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4d4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для добавления судтитров, по названию фильмов и первичной обработки\n",
    "def add_srt(x):\n",
    "    try:\n",
    "        file_path = subtitles_folder2+x+'.srt'\n",
    "        subs = pysrt.open(file_path, encoding='latin-1')\n",
    "        if len(subs) == 0:\n",
    "            subs = pysrt.open(str(file_path), encoding='utf-16') #учитываем альтернативную кодировку\n",
    "        txt = ' '.join([sub.text for sub in subs])\n",
    "        clean_text = clean_subs(txt)\n",
    "        return clean_text\n",
    "    except FileNotFoundError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab0cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавление судтитров\n",
    "df2['subtitles'] = df2['movie'].apply(add_srt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94408d",
   "metadata": {},
   "source": [
    "__Объединие данных__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f8e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94a274",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "\n",
    "- Субтитры загружены и объединены в датасет\n",
    "- Проведена первичная обработка субтитров:\n",
    "    - html тэги заменены на пробел\n",
    "    - комментарии заменены на пробел\n",
    "    - все что не является буквами заменены на пробел\n",
    "    - повторяющиеся пробелы заменены на один пробел\n",
    "    - многоточия заменены на точку\n",
    "    - удалены все что не ascii символы\n",
    "    - удалены первый и последний субтитр (обычно это реклама)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7865ff",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Предобработка и исследовательский анализ данных\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d001a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   movie      404 non-null    object\n",
      " 1   subtitles  273 non-null    object\n",
      " 2   label      404 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 9.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c0b887",
   "metadata": {},
   "source": [
    "- Названия фильмов не несут информацию и сложности диалогов в нем, поэтому: данный признак можно удалить.\n",
    "- В данных присутствуют пропуски, это связано с тем, что в файле excel, были перечислеыы часть фильмов, распрелеленных по отдельным папкам, названия которых, соответствуют уровню сложности языка. Следует удалить подобные записи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f60859cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление признака `movie`\n",
    "df = df.drop('movie', axis=1)\n",
    "# удаление записей с пропусками\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac76f7bf",
   "metadata": {},
   "source": [
    "__Проверим наличие полных дубликатов в данных:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ceae43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество полных дубликатов: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество полных дубликатов: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4fd59",
   "metadata": {},
   "source": [
    "- Надичие дубликарованных строк, связано с наличием одинаковых субтитров в двух изначальных наборах данных, их следует удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28bfd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление дубликатов\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6156a35",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "## Баланс целевого признака\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b199f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B2            136\n",
       "B1             52\n",
       "C1             39\n",
       "A2/A2+         25\n",
       "B1, B2          8\n",
       "A2              6\n",
       "A2/A2+, B1      5\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# вывод количества записей по класскам\n",
    "#df['label'] = df['label'].apply(lambda x: str(x))\n",
    "display(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e067d6",
   "metadata": {},
   "source": [
    "- Как видно из сводной информации, существует дисбаланс класов\n",
    "- Записей по межклассовым (A2/A2+, B1/B2 и тд) не достаточно для обучения классификатора. Небходимо:\n",
    "    - используя [таблицу CEFR/IELS](https://i.postimg.cc/W4YQxZkJ/2023-06-08-15-23-32.png) преобразобать значения в числовой вариант и в последующем решать задачу регрессии\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67b40749",
   "metadata": {},
   "outputs": [],
   "source": [
    "cefr_dict = {'A2': 3.25, #среднее значение крайних значений [3.0:3.5]\n",
    "             'B1': 4.5,  #среднее значение крайних значений [4.0:5.0]\n",
    "             'B2': 6.0, #среднее значение крайних значений [5.5:6.5]\n",
    "             'C1': 7.5, #среднее значение крайних значений [7.0:8.0]\n",
    "             'A2/A2+': 3.5, #верхняя граница\n",
    "             'A2+': 3.5, #верхняя граница\n",
    "             'B1, B2': 5.25, #среднее значение верхнего B1 и низнего B2 [5.0:5.5]\n",
    "             'A2/A2+, B1': 3.75} #среднее значение верхнего A2 и нижнего B1 [3.5:4.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc53d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ielts_index'] = df['label'].apply(lambda x: cefr_dict[x]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977407eb",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "## Рассчет коофициентов удобочитаемости Флеша-Кинкейда\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1bcc72",
   "metadata": {},
   "source": [
    "Тесты на удобочитаемость [Флеша-Кинкейда](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level) — это тесты на удобочитаемость , предназначенные для определения того, насколько труден для понимания отрывок на английском языке . Есть два теста: Flesch Reading-Ease и Flesch-Kincaid Grade Level. Хотя они используют одни и те же основные меры (длина слова и длина предложения), они имеют разные весовые коэффициенты.\n",
    "\n",
    "- Flesch Reading-Ease:\n",
    "$$\n",
    "FRE = 206.835 - (words/sentences)*1.015 - (syllables/words)*84.6\n",
    "$$\n",
    "\n",
    "- Flesch-Kincaid Grade Level:\n",
    "$$\n",
    "FKGL = (words/sentences)*0.39 + (syllables/words)*11.8 - 15.59\n",
    "$$\n",
    "где:\n",
    "- words - количество слов в тексте;\n",
    "- sentences - количество предложений в тексте;\n",
    "- syllables - количество слогов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d63c02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции для рассчета коофициентов удобочитаемости:\n",
    "def statistics(txt):\n",
    "    total_sentences = len(re.split(r\"[.!?]\", txt))\n",
    "    total_words = len(txt.split(' '))\n",
    "    total_syllables = sum(txt.count(g) for g in 'aeoiu') + txt.count('y')/2\n",
    "    return total_sentences, total_words, total_syllables\n",
    "    \n",
    "def flesch_reading_ease(txt):\n",
    "    sentences, words, syllables = statistics(txt)\n",
    "    fres = 206.835 - (words/sentences)*1.015 - (syllables/words)*84.6\n",
    "    return fres\n",
    "    \n",
    "def flesch_kincaid_grade_level(txt):\n",
    "    sentences, words, syllables = statistics(txt)\n",
    "    fkgl = (words/sentences)*0.39 + (syllables/words)*11.8 - 15.59\n",
    "    return fkgl  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6364b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fres'] = df['subtitles'].apply(flesch_reading_ease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed1034a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fkgl'] = df['subtitles'].apply(flesch_kincaid_grade_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f7f66",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "## Токенизация и лематизация текста\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b6e51",
   "metadata": {},
   "source": [
    "- Перед токенизацией текса, необходимо удалить оставшиеся знаки пунктуации и стоп-слова - список слов, которые не влияют на сложность текста, но могут уменьшить точность модели.\n",
    "- Текенизация - это процесс разделения предложений на слова-компоненты.\n",
    "- Лемматизация и стемминг текста. Обычно тексты содержат разные грамматические формы одного и того же слова, а также могут встречаться однокоренные слова. Лемматизация и стемминг преследуют цель привести все встречающиеся словоформы к одной, нормальной словарной форме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95c723b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление знаков пунктуации\n",
    "df['subtitles'] = df['subtitles'].apply(lambda x: PUNCTUATION.sub('', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4da9c5",
   "metadata": {},
   "source": [
    "___________\n",
    "__stopwords/word_tokenize__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c1826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для удаления стоп-слов и токенизации текста\n",
    "def stopwords_tokenize(x):\n",
    "    tokens = word_tokenize(x)\n",
    "    tokenization = [word for word in tokens if not word in stopwords.words('english')]\n",
    "    return tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cef06dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subtitles'] = df['subtitles'].apply(stopwords_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df54b04",
   "metadata": {},
   "source": [
    "_________\n",
    "__stemmer/lemmatizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb5a1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для стеминга и лемматизации\n",
    "def stemmer_lemmatizer(x):\n",
    "    stemmer = [porter_stemmer.stem(s) for s in x]\n",
    "    lemmatizer = [wordnet_lemmatizer.lemmatize(w) for w in stemmer]\n",
    "    return lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3074148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subtitles'] = df['subtitles'].apply(stemmer_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43557284",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "## Рассчет долей слов относительно индекса CEFR\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa0cf5",
   "metadata": {},
   "source": [
    "- Рассчитаем долю слов в тексте, соответствующих списку слов, разделенные по уровням сложности CEFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "984267df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cоздание пустого датафрейма для хранения данных\n",
    "df_info = pd.DataFrame(columns=['a1', 'a2', 'b1', 'b2', 'c1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f3baa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = []\n",
    "# функция рассчета доли слов по уровням сложности\n",
    "def oxford_cefr(x):\n",
    "    a1 = sum(1 for i in x if i in a1_list)\n",
    "    a2 = sum(1 for i in x if i in a2_list)\n",
    "    b1 = sum(1 for i in x if i in b1_list)\n",
    "    b2 = sum(1 for i in x if i in b2_list)\n",
    "    c1 = sum(1 for i in x if i in c1_list)\n",
    "    count_word = a1+a2+b1+b2+c1\n",
    "    a1 = a1/count_word\n",
    "    a2 = a2/count_word\n",
    "    b1 = b1/count_word\n",
    "    b2 = b2/count_word\n",
    "    c1 = c1/count_word\n",
    "    data_info.append({'a1':a1, 'a2':a2, 'b1':b1, 'b2': b2, 'c1':c1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af19b99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "270    None\n",
       "271    None\n",
       "272    None\n",
       "273    None\n",
       "274    None\n",
       "Name: subtitles, Length: 271, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subtitles'].apply(oxford_cefr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f7bb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем все записи в датасете с помощью функции concat\n",
    "df_info = pd.concat([df_info, pd.DataFrame(data_info)], ignore_index=True)\n",
    "df = pd.concat([df, df_info], axis=1).copy()\n",
    "# удаление записей с пропусками\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e94c8",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "\n",
    "- Изучена общая информация.\n",
    "- Обработаны дубликаты и пропуски в данных.\n",
    "- Выявлен дисбаланс классов.\n",
    "- Удалены стоп-слова.\n",
    "- Проведена токенизация и лематизация текста.\n",
    "- Рассчитаны дополнительные признаки:\n",
    "    - Flesch Reading-Ease\n",
    "    - Flesch-Kincaid Grade Level\n",
    "    - Доли слов относительно индекса CEFR\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda82ecd",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "# Разработка модели ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a34f39",
   "metadata": {},
   "source": [
    "- Для обучения моделей машинного обучения по прежнему не хватает записей, но так как субтитры в большенстве своем достаточно длинные, мы в праве разделить их по определенному количеству слов, тем самым увеличив количество записей. При этом рассчитанные ранее статистические данные следует оставить без изменений, тк они были рассчитаны на всем тексте и обладают большей точностью, по сравнению с теми, которые мы можем рассчитать на части данных.\n",
    "   - выбырем количество: 100 слов \n",
    "- Некоторые записи могут содержать меньшее число слов, их следует исключить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e897bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определение количества слов в субтитрах\n",
    "df['len'] = df['subtitles'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81b7dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['len']>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68be3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cоздание пустого датафрейма для хранения данных\n",
    "df_div = pd.DataFrame(columns=['subtitles','a1', 'a2', 'b1', 'b2', 'c1', 'fres', 'fkgl','label', 'ielts_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bdee4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для разделения субтитров\n",
    "len_div = 100 #количество слов в подвыборке, для увеличения наблюдений\n",
    "data = []\n",
    "def text_division(x):\n",
    "    for i in range(len(x['subtitles'])//len_div):\n",
    "        data.append({'subtitles': ' '.join(x['subtitles'][i*len_div:(i+1)*len_div+1]), \n",
    "                     'a1': x['a1'],\n",
    "                     'a2': x['a2'],\n",
    "                     'b1': x['b1'],\n",
    "                     'b2': x['b2'],\n",
    "                     'c1': x['c1'],\n",
    "                     'fres': x['fres'],\n",
    "                     'fkgl': x['fkgl'],\n",
    "                     'label': x['label'],\n",
    "                     'ielts_index': x['ielts_index']})               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "966efd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "265    None\n",
       "266    None\n",
       "267    None\n",
       "268    None\n",
       "270    None\n",
       "Length: 263, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(text_division, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7caf82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jбъединяем все записи в датасете с помощью функции concat\n",
    "df = pd.concat([df_div, pd.DataFrame(data)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645745ee",
   "metadata": {},
   "source": [
    "__Выделение обучающей и тестовой выборок__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac292a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер выборок: (7826, 8);(1957, 8);(7826, 1);(1957, 1)\n"
     ]
    }
   ],
   "source": [
    "# признаки для обучения\n",
    "X = ['subtitles', 'a1', 'a2', 'b1', 'b2', 'c1', 'fres', 'fkgl']\n",
    "# целевой признак\n",
    "y = ['ielts_index']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=RANDOM_SEED)\n",
    "print(f'Размер выборок: {X_train.shape};{X_test.shape};{y_train.shape};{y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6144163",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "- Увеличен размер выборки за счет разделения субтитров на несколько записей.\n",
    "- Датафрейм разделен на обучающую и тестовую выборки.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b08262",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "## RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14dfb5",
   "metadata": {},
   "source": [
    "- Для обучения модели, необходима векторизация текстовой информации. Поскольку текстовые данные представлены в виде последовательности слов или символов, их необходимо преобразовать в числовой формат, чтобы модель могла работать с ними. Одним из популярных методов векторизации текста является TF-IDF (Term Frequency-Inverse Document Frequency). Этот метод присваивает каждому слову в тексте числовое значение, основанное на его частоте встречаемости в документе (Term Frequency) и обратной частоте встречаемости в корпусе документов (Inverse Document Frequency). Результатом векторизации текста с использованием TF-IDF является числовое представление текста, где каждое слово представлено числовым значением, отражающим его важность в контексте данного текста. Так же необходимо ограничить размерность матрицы, тк в случае сохранения всех параметров, потребуется много времени для реализации данного алгоритма обучения.\n",
    "\n",
    "__TF-IDF векторизация__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "456ad9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность обучающей матрицы TF-IDF: (7826, 25)\n",
      "Размерность тестовой матрицы TF-IDF: (1957, 25)\n"
     ]
    }
   ],
   "source": [
    "# Векторизация столбца 'subtitles' с помощью TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=25)\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train['subtitles'])\n",
    "X_test_vectorized = vectorizer.transform(X_test['subtitles'])\n",
    "# Вывод размерности матрицы TF-IDF\n",
    "print(\"Размерность обучающей матрицы TF-IDF:\", X_train_vectorized.shape)\n",
    "print(\"Размерность тестовой матрицы TF-IDF:\", X_test_vectorized.shape)\n",
    "\n",
    "# Преобразование векторизованного столбца 'subtitles' в массив NumPy\n",
    "X_train_vectorized = X_train_vectorized.toarray()\n",
    "X_test_vectorized = X_test_vectorized.toarray()\n",
    "\n",
    "# Объединение данных в один набор\n",
    "X_train_combined = np.hstack((X_train_vectorized, X_train.drop('subtitles', axis=1)))\n",
    "X_test_combined = np.hstack((X_test_vectorized, X_test.drop('subtitles', axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b73290",
   "metadata": {},
   "source": [
    "__Обучение модели__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a3643e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# гиперпараметры модели\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [5, 7],\n",
    "    'min_samples_split': [2, 3]\n",
    "}\n",
    "# параметры модели\n",
    "model_RF = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "# объект метрики MAE\n",
    "scorer = make_scorer(mean_absolute_error)\n",
    "# параметры RandomizedSearchCV\n",
    "random_search_RF = RandomizedSearchCV(estimator=model_RF,\n",
    "                                      param_distributions=param_grid,\n",
    "                                      n_iter=100,\n",
    "                                      cv=3,\n",
    "                                      verbose=True,\n",
    "                                      random_state=RANDOM_SEED,\n",
    "                                      scoring=scorer,\n",
    "                                      n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d61981e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Оптимальные гиперпараметры:\n",
      "{'n_estimators': 150, 'min_samples_split': 2, 'max_depth': 5}\n",
      "0.5313494403967689\n"
     ]
    }
   ],
   "source": [
    "# обучение модели\n",
    "random_search_RF.fit(X_train_combined, y_train.values.ravel())\n",
    "# сохраним лучшую модель\n",
    "best_model_RF = random_search_RF.best_estimator_\n",
    "# сохраним лучшее значение метрики\n",
    "final_metrics_RF = random_search_RF.best_score_\n",
    "# вывод результатов\n",
    "print(f'Оптимальные гиперпараметры:\\n{random_search_RF.best_params_}\\n{final_metrics_RF}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77507164",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "- Оптимальные гитерпараметры для алгоритма RandomForest:\n",
    "    - 'n_estimators': 150\n",
    "    - 'min_samples_split': 2\n",
    "    - 'max_depth': 5\n",
    "    \n",
    "- Метрика качества MAE на обучающих данных при кроссвалидации составляет: 0.53\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73653cf9",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "## CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8957d5",
   "metadata": {},
   "source": [
    "- CatBoost - это градиентный бустинговый алгоритм, разработанный компанией Yandex. Он является мощным инструментом для задач классификации и регрессии, который обладает рядом преимуществ и особенностей.\n",
    "\n",
    "- Одной из основных преимуществ CatBoost является его способность работать напрямую с категориальными признаками, включая текстовые данные. В отличие от многих других алгоритмов, CatBoost может обрабатывать категориальные признаки без необходимости их предварительной векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ad6d22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тестовые признаки \n",
    "text_features = ['subtitles']\n",
    "# pool\n",
    "train_pool = Pool(X_train,\n",
    "                  label=y_train,\n",
    "                  text_features=text_features)\n",
    "\n",
    "test_pool = Pool(X_test,\n",
    "                 text_features=text_features)\n",
    "# целевой признак тестовой выборки\n",
    "y_test_cb = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd72d1b8",
   "metadata": {},
   "source": [
    "__optuna-подбор оптимальных гиперпараметров__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7a87317f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7043, 8), (7043, 1), (1957, 8), (1957, 1), (783, 8), (783, 1))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выборки для подбора гиперпараметров CatBoost\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df[X], df[y], test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=RANDOM_SEED)\n",
    "# размер выборок\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97c40795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# гиперпараметры optuna\n",
    "def objective(trial):\n",
    "    param = {}\n",
    "    param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
    "    param['depth'] = trial.suggest_int('depth', 9, 15)\n",
    "    param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
    "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
    "    param['grow_policy'] = 'Depthwise'\n",
    "    param['iterations'] = 1000\n",
    "    param['use_best_model'] = True\n",
    "    param['eval_metric'] = 'MAE'\n",
    "    param['od_type'] = 'iter'\n",
    "    param['od_wait'] = 20\n",
    "    param['random_state'] = RANDOM_SEED\n",
    "    param['logging_level'] = 'Silent'\n",
    "    param['text_features'] = text_features\n",
    "    \n",
    "    regressor = CatBoostRegressor(**param)\n",
    "\n",
    "    regressor.fit(X_train.copy(), y_train.copy(),\n",
    "                  eval_set=[(X_test.copy(), y_test.copy())],\n",
    "                  early_stopping_rounds=EARLY_STOPPING_ROUND)\n",
    "    loss = mean_absolute_error(y_valid, regressor.predict(X_valid.copy()))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97efba81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-03 19:07:55,451] A new study created in memory with name: catboost-seed42\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:13:16,118] Trial 5 finished with value: 0.11235527533125683 and parameters: {'learning_rate': 0.02, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 32}. Best is trial 5 with value: 0.11235527533125683.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:14:24,602] Trial 3 finished with value: 0.131822919967549 and parameters: {'learning_rate': 0.017, 'depth': 9, 'l2_leaf_reg': 2.0, 'min_child_samples': 8}. Best is trial 5 with value: 0.11235527533125683.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:16:17,435] Trial 8 finished with value: 0.12876226564864462 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 10, 'l2_leaf_reg': 4.0, 'min_child_samples': 8}. Best is trial 5 with value: 0.11235527533125683.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:16:45,440] Trial 7 finished with value: 0.09299385221785232 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 13, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 7 with value: 0.09299385221785232.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:17:46,733] Trial 1 finished with value: 0.09159208023365156 and parameters: {'learning_rate': 0.017, 'depth': 14, 'l2_leaf_reg': 5.5, 'min_child_samples': 32}. Best is trial 1 with value: 0.09159208023365156.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:20:33,467] Trial 0 finished with value: 0.11059168276008682 and parameters: {'learning_rate': 0.014, 'depth': 11, 'l2_leaf_reg': 1.0, 'min_child_samples': 4}. Best is trial 1 with value: 0.09159208023365156.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:21:29,756] Trial 2 finished with value: 0.09038012162176244 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:25:07,549] Trial 4 finished with value: 0.0997017905898607 and parameters: {'learning_rate': 0.02, 'depth': 13, 'l2_leaf_reg': 1.5, 'min_child_samples': 4}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-03 19:26:51,243] Trial 15 finished with value: 0.10743209239881818 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 11, 'l2_leaf_reg': 5.0, 'min_child_samples': 32}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:26:57,911] Trial 6 finished with value: 0.09722524886491622 and parameters: {'learning_rate': 0.014, 'depth': 14, 'l2_leaf_reg': 3.0, 'min_child_samples': 8}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:31:53,567] Trial 14 finished with value: 0.09371475702760247 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 4.0, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:32:58,963] Trial 16 finished with value: 0.09989806019547569 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 12, 'l2_leaf_reg': 1.5, 'min_child_samples': 8}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:33:31,642] Trial 9 finished with value: 0.09836455530121371 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 15, 'l2_leaf_reg': 3.5, 'min_child_samples': 4}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:35:04,214] Trial 10 finished with value: 0.10252028298045607 and parameters: {'learning_rate': 0.017, 'depth': 14, 'l2_leaf_reg': 4.0, 'min_child_samples': 4}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:36:07,576] Trial 17 finished with value: 0.13327704895793493 and parameters: {'learning_rate': 0.012, 'depth': 11, 'l2_leaf_reg': 5.5, 'min_child_samples': 8}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:36:32,856] Trial 18 finished with value: 0.10079822056421966 and parameters: {'learning_rate': 0.014, 'depth': 13, 'l2_leaf_reg': 4.5, 'min_child_samples': 32}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:37:38,200] Trial 13 finished with value: 0.09301645520676272 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 8}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-03 19:40:25,698] Trial 19 finished with value: 0.11227949550735124 and parameters: {'learning_rate': 0.011, 'depth': 13, 'l2_leaf_reg': 2.5, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
      "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
      "[I 2023-06-03 19:52:21,895] Trial 22 finished with value: 0.11728346992337901 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
      "[I 2023-06-03 19:53:47,323] Trial 23 finished with value: 0.10662109775601156 and parameters: {'learning_rate': 0.011, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
      "[I 2023-06-03 20:07:07,717] Trial 12 finished with value: 0.09070113988838173 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 3.0, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
      "[I 2023-06-03 20:07:50,135] Trial 11 finished with value: 0.09240136692804589 and parameters: {'learning_rate': 0.012, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
      "[I 2023-06-03 20:16:24,282] Trial 21 finished with value: 0.1063296214759433 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
      "[I 2023-06-03 20:16:38,527] Trial 20 finished with value: 0.10179649041723511 and parameters: {'learning_rate': 0.011, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
      "[I 2023-06-03 20:18:37,256] Trial 24 finished with value: 0.09982160262124344 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
      "[I 2023-06-03 20:20:07,934] Trial 26 finished with value: 0.10050195377238245 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
      "[I 2023-06-03 20:22:06,336] Trial 25 finished with value: 0.08805955872892557 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 1}. Best is trial 25 with value: 0.08805955872892557.\n",
      "[I 2023-06-03 20:22:39,486] Trial 27 finished with value: 0.09063355848597779 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 1}. Best is trial 25 with value: 0.08805955872892557.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11h 54min 56s, sys: 7min 26s, total: 12h 2min 23s\n",
      "Wall time: 1h 14min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "study = optuna.create_study(study_name=f'catboost-seed{RANDOM_SEED}')\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1, timeout=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9fbea7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08805955872892557"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лучшая метрика\n",
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a94d2092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.016,\n",
       " 'depth': 15,\n",
       " 'l2_leaf_reg': 2.5,\n",
       " 'min_child_samples': 1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оптимальные гиперпараметры\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8b6fe",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "- Оптимальные гитерпараметры для алгоритма CatBoost, при использовании алгоритма optuna:\n",
    "    - 'learning_rate': 0.016\n",
    "    - 'depth': 15\n",
    "    - 'l2_leaf_reg': 2.5\n",
    "    - 'min_child_samples': 1\n",
    "    \n",
    "- Метрика качества MAE на обучающих данных при кроссвалидации составляет: 0.09\n",
    "    ____________\n",
    "    \n",
    "- Для дальнейшего обучения выбираем алгоритм CatBoost, показывающий лучшую метрику качества. Однако, чать параметром не будет использоваться далее, что увеличит скорость обучения и предсказаний. В дальнейшем, при необходимости более точных данных, можно их можно будет использовать в модели.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e95803",
   "metadata": {},
   "source": [
    "__Обучение модели__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3b8bbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# гиперпараметры модели\n",
    "parameters = {'verbose': 100,\n",
    "              'text_features': ['subtitles'],\n",
    "              'eval_metric': 'MAE',\n",
    "              'iterations': 1000,\n",
    "              'learning_rate': 0.2,\n",
    "              'random_seed':RANDOM_SEED,\n",
    "              'early_stopping_rounds': 30\n",
    "             }\n",
    "# параметры модели\n",
    "regressor = CatBoostRegressor(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8272587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9101034\ttotal: 95.9ms\tremaining: 1m 35s\n",
      "100:\tlearn: 0.1426646\ttotal: 3.78s\tremaining: 33.7s\n",
      "200:\tlearn: 0.0779433\ttotal: 7.45s\tremaining: 29.6s\n",
      "300:\tlearn: 0.0562830\ttotal: 11.2s\tremaining: 26.1s\n",
      "400:\tlearn: 0.0441051\ttotal: 15s\tremaining: 22.3s\n",
      "500:\tlearn: 0.0359515\ttotal: 18.6s\tremaining: 18.5s\n",
      "600:\tlearn: 0.0305177\ttotal: 22.3s\tremaining: 14.8s\n",
      "700:\tlearn: 0.0263480\ttotal: 26s\tremaining: 11.1s\n",
      "800:\tlearn: 0.0228443\ttotal: 29.7s\tremaining: 7.37s\n",
      "900:\tlearn: 0.0200240\ttotal: 33.4s\tremaining: 3.67s\n",
      "999:\tlearn: 0.0177868\ttotal: 37s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2972b65c0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучение модели\n",
    "regressor.fit(train_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439a000",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "## Проверка модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d156ab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя абсолютная ошибка (MAE): 0.05040942850434126\n"
     ]
    }
   ],
   "source": [
    "# предказание данных\n",
    "predict = regressor.predict(test_pool)\n",
    "mae = mean_absolute_error(y_test_cb, predict)\n",
    "# вывод результатов\n",
    "print(\"Средняя абсолютная ошибка (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a526795",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "382647ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение итоговой модели\n",
    "regressor.save_model('catboost_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8f327",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "\n",
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde2eb9",
   "metadata": {},
   "source": [
    "- В ходе проведения исследования была выполнена предобработка данных, включающая очистку и лемматизацию текстовых признаков. Для векторизации текста был применен метод TF-IDF, который позволяет представить тексты в виде числовых признаков, учитывающих важность каждого термина в документе.\n",
    "\n",
    "- Для настройки гиперпараметров модели CatBoost был использован фреймворк Optuna. Optuna провел исследование пространства гиперпараметров, оценивая производительность модели с различными комбинациями параметров. Целевая метрика, в данном случае MAE, была определена для оптимизации. В результате подбора гиперпараметров были получены оптимальные значения, которые позволяют достичь наилучшей производительности модели CatBoost на данной задаче и составиляют 0.05 на тестовой выборке.\n",
    "\n",
    "- Полученная модель будет использоваться в разработке сервиса, предназначенного для определения уровня сложности английского языка в фильмах. Этот сервис будет доступен через платформу Streamlit, что позволит пользователям оценивать и анализировать сложность субтитров и основываться на предсказанных значениях индекса IELTS или CEFR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
